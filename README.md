# Deep Learning Journey with Practical Hands-On

Welcome to my repository, which serves as a journal of my educational journey in the field of Deep Learning. Here you will find a series of practical exercises and real-world applications that have marked my path of learning. Our journey begins with an introduction to the fundamental concept of the Perceptron and dives deeply into the complexities of the inner workings of Deep Neural Networks. We will delve into the various loss, activation, and optimization functions in detail, understanding their behavior and, of course, how these are integrated into the practical implementation of Artificial Neural Networks. This path is paved with strategies for selecting hyperparameters, all within the framework of the TensorFlow Keras library.

Furthermore, I will venture into exploration and experimentation with TensorFlow 2.0, offering a fresh and up-to-date perspective.

Among the problems I have tackled are the classification of images, text, and audio, using various techniques and approaches.

## Learning Path

The learning path is structured into various sections, each with its own set of Jupyter notebooks for hands-on practice:

### The Perceptron

1. `4 - Visualizacion del limite de decision del Perceptron.ipynb`
2. `5 - Clasificación de imágenes con el Perceptrón.ipynb`

### Deep Artificial Neural Networks

3. `6 - Visualizando el limite de decision del Perceptrn Multicapa.ipynb`

### Loss and Optimization Functions in ANNs

4. `7 - Clasificación de imágenes con el Perceptrón Multicapa.ipynb`

### Training Deep ANNs

5. `8 - Clasificación de audio con el Perceptrón Multicapa.ipynb`
6. `9 - Clasificación de audio con el Perceptrón Multicapa II.ipynb`

### Vectorized Implementation of ANNs

7. `7 - Implementación Vectorizada de RNAs.ipynb`

### Regression and Classification with ANNs

### Introduction to Keras

8. `10 - Implementando una RNA con Keras.ipynb`
9. `11 - Limite de decisión de una RNA profunda.ipynb`
10. `12 - Clasificación de audio con Keras.ipynb`
11. `13 - Regresion con Keras.ipynb`

### Activation Functions

12. `14 - Visualización de las funciones de activación.ipynb`
13. `15 - Clasificacion de sentimientos.ipynb`

### Optimization Functions

14. `16 - Clasificacion de texto con Mini-Batch Gradient Descent.ipynb`
15. `17 - Clasificacion de texto con Stochastic Gradient Descent.ipynb`
16. `18 - Exponentially weighted moving average.ipynb`
17. `19 - Clasificacion de texto con Momentum Gradient Descent.ipynb`
18. `20 - Clasificacion de texto con RMSprop.ipynb`
19. `21 - Clasificacion de texto con Adam.ipynb`

### Hyperparameter Selection

20. `22 - Seleccion de hiperpara╠ümetros con Keras Tuner.ipynb`
21. `23 - Seleccion de hiperparametros y clasificacio╠ün de texto.ipynb`

### TensorFlow 2.0

22. `24 - Tensores y operaciones con tensores.ipynb`
23. `25 - Creacion de una funcion de error personalizada.ipynb`
24. `26 - Creacion de otros componentes personalizados con Tensorflow.ipynb`

---------------------------------------------------------------------------------------------------------------------------------------------------------

# Ruta de Aprendizaje en Deep Learning con Ejercicios Prácticos

Bienvenidos a mi repositorio, el cual es el diario de mi viaje formativo en el ámbito del Deep Learning. Aquí encontrarán una colección de ejercicios prácticos y aplicaciones reales que han jalonado mi aprendizaje. Nuestro recorrido comienza con la introducción al concepto fundamental del Perceptrón y se sumerge de lleno en las complejidades del funcionamiento interno de las Redes Neuronales Profundas. Exploraremos en detalle las diversas funciones de pérdida, activación y optimización, así como su comportamiento y, por supuesto, cómo estas se ensamblan en la implementación práctica de las Redes Neuronales Artificiales. Este camino está pavimentado con estrategias para la elección de hiperparámetros, todo ello bajo el amparo de la biblioteca Keras de TensorFlow.

Además, incursionaré en la exploración y experimentación con TensorFlow 2.0, ofreciendo una perspectiva fresca y actualizada.

Entre los problemas que he abordado se incluyen: la clasificación de imágenes, texto y audio, utilizando diversas técnicas y enfoques.

## Ruta de Aprendizaje

La ruta de aprendizaje está estructurada en varias secciones, cada una con sus respectivos cuadernos Jupyter para la práctica:

### El Perceptrón

1. `4 - Visualizacion del limite de decision del Perceptron.ipynb`
2. `5 - Clasificación de imágenes con el Perceptrón.ipynb`

### Redes Neuronales Artificiales Profundas

3. `6 - Visualizando el limite de decision del Perceptrn Multicapa.ipynb`

### Función de Error y de Optimización en RNAs

4. `7 - Clasificación de imágenes con el Perceptrón Multicapa.ipynb`

### Entrenamiento de Redes Neuronales Artificiales Profundas

5. `8 - Clasificación de audio con el Perceptrón Multicapa.ipynb`
6. `9 - Clasificación de audio con el Perceptrón Multicapa II.ipynb`

### Implementación Vectorizada de RNAs

7. `7 - Implementación Vectorizada de RNAs.ipynb`

### Regresión y Clasificación con RNAs

### Introducción a Keras

8. `10 - Implementando una RNA con Keras.ipynb`
9. `11 - Limite de decisión de una RNA profunda.ipynb`
10. `12 - Clasificación de audio con Keras.ipynb`
11. `13 - Regresion con Keras.ipynb`

### Funciones de Activación

12. `14 - Visualización de las funciones de activación.ipynb`
13. `15 - Clasificacion de sentimientos.ipynb`

### Funciones de Optimización

14. `16 - Clasificacion de texto con Mini-Batch Gradient Descent.ipynb`
15. `17 - Clasificacion de texto con Stochastic Gradient Descent.ipynb`
16. `18 - Exponentially weighted moving average.ipynb`
17. `19 - Clasificacion de texto con Momentum Gradient Descent.ipynb`
18. `20 - Clasificacion de texto con RMSprop.ipynb`
19. `21 - Clasificacion de texto con Adam.ipynb`

### Selección de Hiperparámetros

20. `22 - Seleccion de hiperparámetros con Keras Tuner.ipynb`
21. `23 - Seleccion de hiperparametros y clasificación de texto.ipynb`

### TensorFlow 2.0

22. `24 - Tensores y operaciones con tensores.ipynb`
23. `25 - Creacion de una funcion de error personalizada.ipynb`
24. `26 - Creacion de otros componentes personalizados con Tensorflow.ipynb`
