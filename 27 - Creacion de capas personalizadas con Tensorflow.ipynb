{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación de capas personalizadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En ciertas ocasiones es posible que se desee implementar una nueva capa de la red neuronal artificial para la que no existe una implementación en Tensorflow o Keras. En estos casos podemos utilizar Tensorflow para crear capas personalizadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando el conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_housing = datasets.boston_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.23247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.142</td>\n",
       "      <td>91.7</td>\n",
       "      <td>3.9769</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>18.72</td>\n",
       "      <td>15.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02177</td>\n",
       "      <td>82.5</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.415</td>\n",
       "      <td>7.610</td>\n",
       "      <td>15.7</td>\n",
       "      <td>6.2700</td>\n",
       "      <td>2.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>395.38</td>\n",
       "      <td>3.11</td>\n",
       "      <td>42.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.89822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631</td>\n",
       "      <td>4.970</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.3325</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>375.52</td>\n",
       "      <td>3.26</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.515</td>\n",
       "      <td>6.037</td>\n",
       "      <td>34.5</td>\n",
       "      <td>5.9853</td>\n",
       "      <td>5.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>8.01</td>\n",
       "      <td>21.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.69311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713</td>\n",
       "      <td>6.376</td>\n",
       "      <td>88.4</td>\n",
       "      <td>2.5671</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>391.43</td>\n",
       "      <td>14.65</td>\n",
       "      <td>17.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.28392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.493</td>\n",
       "      <td>5.708</td>\n",
       "      <td>74.3</td>\n",
       "      <td>4.7211</td>\n",
       "      <td>5.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>391.13</td>\n",
       "      <td>11.74</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.18702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.700</td>\n",
       "      <td>5.536</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.5804</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>23.60</td>\n",
       "      <td>11.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.09740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.871</td>\n",
       "      <td>5.468</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.4118</td>\n",
       "      <td>5.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>26.42</td>\n",
       "      <td>15.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.15505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.871</td>\n",
       "      <td>5.628</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.5166</td>\n",
       "      <td>5.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>169.27</td>\n",
       "      <td>16.65</td>\n",
       "      <td>15.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.62864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.624</td>\n",
       "      <td>5.019</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.4394</td>\n",
       "      <td>4.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>34.41</td>\n",
       "      <td>14.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS   RAD    TAX  \\\n",
       "0  1.23247   0.0   8.14   0.0  0.538  6.142   91.7  3.9769   4.0  307.0   \n",
       "1  0.02177  82.5   2.03   0.0  0.415  7.610   15.7  6.2700   2.0  348.0   \n",
       "2  4.89822   0.0  18.10   0.0  0.631  4.970  100.0  1.3325  24.0  666.0   \n",
       "3  0.03961   0.0   5.19   0.0  0.515  6.037   34.5  5.9853   5.0  224.0   \n",
       "4  3.69311   0.0  18.10   0.0  0.713  6.376   88.4  2.5671  24.0  666.0   \n",
       "5  0.28392   0.0   7.38   0.0  0.493  5.708   74.3  4.7211   5.0  287.0   \n",
       "6  9.18702   0.0  18.10   0.0  0.700  5.536  100.0  1.5804  24.0  666.0   \n",
       "7  4.09740   0.0  19.58   0.0  0.871  5.468  100.0  1.4118   5.0  403.0   \n",
       "8  2.15505   0.0  19.58   0.0  0.871  5.628  100.0  1.5166   5.0  403.0   \n",
       "9  1.62864   0.0  21.89   0.0  0.624  5.019  100.0  1.4394   4.0  437.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     21.0  396.90  18.72  15.2  \n",
       "1     14.7  395.38   3.11  42.3  \n",
       "2     20.2  375.52   3.26  50.0  \n",
       "3     20.2  396.90   8.01  21.1  \n",
       "4     20.2  391.43  14.65  17.7  \n",
       "5     19.6  391.13  11.74  18.5  \n",
       "6     20.2  396.90  23.60  11.3  \n",
       "7     14.7  396.90  26.42  15.6  \n",
       "8     14.7  169.27  16.65  15.6  \n",
       "9     21.2  396.90  34.41  14.4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "features = [\"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"DIS\", \"RAD\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\", \"MEDV\"]\n",
    "\n",
    "df_train = pd.DataFrame(np.column_stack([X_train, y_train]), columns=features)\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escalando el conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "\n",
    "X_train_prep = scaler.fit_transform(X_train)\n",
    "X_val_prep = scaler.transform(X_val)\n",
    "X_test_prep = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definicion de la arquitectura de la Red Neuronal Artificial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de capas sin parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las capas sin parámetros aplican transformaciones sobre los valores de entrada. Algunos ejemplos de capas de este tipo que se encuentran implementados en Keras son: _keras.layers.Flatten_ o _keras.layers.ReLU_. \n",
    "\n",
    "En estos casos, la mejor forma de crear este tipo de capas es desarrollar una función personalizada y utilizarla junto con la construcción _keras.layers.Lambda_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# Capa personalizada que eleva al cuadrado los valores de entrada\n",
    "square_layer = keras.layers.Lambda(lambda x: tf.square(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta capa se utiliza de la misma forma que el resto de capas que se encuentran implementadas en Keras por defecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = models.Sequential()\n",
    "\n",
    "network.add(layers.Dense(30, activation='relu', input_shape=X_train.shape[1:]))\n",
    "network.add(layers.Dense(10, activation='relu'))\n",
    "network.add(square_layer)\n",
    "network.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 30)                420       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                310       \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 10)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 741 (2.89 KB)\n",
      "Trainable params: 741 (2.89 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(\n",
    "    loss='mean_squared_error',\n",
    "    optimizer='adam',\n",
    "    metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13/13 [==============================] - 3s 57ms/step - loss: 615.2615 - mae: 23.0040 - val_loss: 622.9422 - val_mae: 23.4208\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 587.7448 - mae: 22.0857 - val_loss: 607.1354 - val_mae: 22.9733\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 574.5662 - mae: 21.6830 - val_loss: 598.5243 - val_mae: 22.7905\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 562.5639 - mae: 21.4432 - val_loss: 585.7906 - val_mae: 22.5645\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 542.8311 - mae: 21.0375 - val_loss: 557.6268 - val_mae: 21.9307\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 510.8440 - mae: 20.3214 - val_loss: 514.9229 - val_mae: 20.8699\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 464.8885 - mae: 19.2770 - val_loss: 467.4315 - val_mae: 19.4628\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 417.8246 - mae: 18.0713 - val_loss: 425.0238 - val_mae: 18.7706\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 374.6888 - mae: 16.9424 - val_loss: 401.7393 - val_mae: 18.5815\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 351.9693 - mae: 16.2916 - val_loss: 377.5984 - val_mae: 17.9537\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 327.1112 - mae: 15.7009 - val_loss: 346.4221 - val_mae: 17.1986\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 300.7812 - mae: 15.0086 - val_loss: 313.6794 - val_mae: 16.4296\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 275.4940 - mae: 14.2869 - val_loss: 281.0182 - val_mae: 15.5291\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 248.6805 - mae: 13.5296 - val_loss: 249.1340 - val_mae: 14.5058\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 221.4026 - mae: 12.7615 - val_loss: 222.7237 - val_mae: 13.5322\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 197.8233 - mae: 12.0260 - val_loss: 197.7220 - val_mae: 12.5672\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 176.0245 - mae: 11.2796 - val_loss: 175.6242 - val_mae: 11.6075\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 157.8673 - mae: 10.6261 - val_loss: 160.8831 - val_mae: 11.1190\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 145.1149 - mae: 10.1611 - val_loss: 148.0383 - val_mae: 10.6451\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 133.6458 - mae: 9.6203 - val_loss: 138.4042 - val_mae: 10.2764\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 123.6576 - mae: 9.2074 - val_loss: 130.4296 - val_mae: 9.9190\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 115.6535 - mae: 8.8874 - val_loss: 122.7476 - val_mae: 9.5811\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 107.8485 - mae: 8.5236 - val_loss: 116.8007 - val_mae: 9.3754\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 101.6234 - mae: 8.2420 - val_loss: 109.7519 - val_mae: 9.0649\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 95.5193 - mae: 7.9760 - val_loss: 103.1266 - val_mae: 8.7527\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 90.0216 - mae: 7.6719 - val_loss: 96.6705 - val_mae: 8.4281\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 83.6428 - mae: 7.3679 - val_loss: 89.9177 - val_mae: 8.0917\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 78.6416 - mae: 7.1146 - val_loss: 85.1513 - val_mae: 7.8445\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 73.6635 - mae: 6.8948 - val_loss: 80.3966 - val_mae: 7.6553\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 68.7741 - mae: 6.6080 - val_loss: 74.0891 - val_mae: 7.2889\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 64.2911 - mae: 6.3813 - val_loss: 67.9747 - val_mae: 6.9785\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 59.8744 - mae: 6.1268 - val_loss: 62.8707 - val_mae: 6.6876\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 55.6739 - mae: 5.9081 - val_loss: 57.5118 - val_mae: 6.3797\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 51.5835 - mae: 5.6456 - val_loss: 52.2631 - val_mae: 6.0484\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 47.9220 - mae: 5.4290 - val_loss: 47.4740 - val_mae: 5.7786\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 44.5140 - mae: 5.2292 - val_loss: 43.0769 - val_mae: 5.4731\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 41.1681 - mae: 4.9957 - val_loss: 39.1111 - val_mae: 5.2581\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 37.9740 - mae: 4.8211 - val_loss: 35.2399 - val_mae: 4.9474\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 35.1733 - mae: 4.6262 - val_loss: 31.4963 - val_mae: 4.6908\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 32.4687 - mae: 4.4228 - val_loss: 28.6132 - val_mae: 4.4746\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 30.3619 - mae: 4.2841 - val_loss: 26.0445 - val_mae: 4.2967\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 28.1338 - mae: 4.1620 - val_loss: 23.2078 - val_mae: 4.0282\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 26.6640 - mae: 4.0338 - val_loss: 21.4252 - val_mae: 3.8814\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 24.3124 - mae: 3.8271 - val_loss: 19.1645 - val_mae: 3.6367\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 23.0873 - mae: 3.7523 - val_loss: 17.1380 - val_mae: 3.4795\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 21.4992 - mae: 3.5886 - val_loss: 15.7771 - val_mae: 3.2709\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 20.0809 - mae: 3.4642 - val_loss: 14.6524 - val_mae: 3.1607\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 18.9818 - mae: 3.3639 - val_loss: 13.4745 - val_mae: 3.0179\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 18.5182 - mae: 3.3191 - val_loss: 12.3509 - val_mae: 2.8820\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 17.2863 - mae: 3.2212 - val_loss: 11.6287 - val_mae: 2.7907\n"
     ]
    }
   ],
   "source": [
    "history = network.fit(X_train_prep, \n",
    "                      y_train, \n",
    "                      epochs=50, \n",
    "                      validation_data=(X_val_prep, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[22.524328 ],\n",
       "       [50.969437 ],\n",
       "       [14.850312 ],\n",
       "       [13.330548 ],\n",
       "       [19.702993 ],\n",
       "       [25.45155  ],\n",
       "       [39.203743 ],\n",
       "       [49.71373  ],\n",
       "       [22.702524 ],\n",
       "       [17.108263 ],\n",
       "       [20.086046 ],\n",
       "       [25.014519 ],\n",
       "       [15.485461 ],\n",
       "       [17.014172 ],\n",
       "       [18.3102   ],\n",
       "       [ 6.366857 ],\n",
       "       [10.021463 ],\n",
       "       [11.385876 ],\n",
       "       [43.50708  ],\n",
       "       [19.24035  ],\n",
       "       [22.97764  ],\n",
       "       [ 9.969568 ],\n",
       "       [25.267511 ],\n",
       "       [30.5914   ],\n",
       "       [22.647951 ],\n",
       "       [26.722635 ],\n",
       "       [10.5821495],\n",
       "       [21.340649 ],\n",
       "       [20.743612 ],\n",
       "       [24.756197 ],\n",
       "       [20.555672 ],\n",
       "       [23.871695 ],\n",
       "       [33.92633  ],\n",
       "       [21.653076 ],\n",
       "       [24.132566 ],\n",
       "       [15.228576 ],\n",
       "       [29.074083 ],\n",
       "       [36.9334   ],\n",
       "       [18.25167  ],\n",
       "       [20.208876 ],\n",
       "       [43.000732 ],\n",
       "       [35.627743 ],\n",
       "       [ 7.1949506],\n",
       "       [21.489798 ],\n",
       "       [15.270525 ],\n",
       "       [31.366821 ],\n",
       "       [36.97838  ],\n",
       "       [24.828995 ],\n",
       "       [14.247117 ],\n",
       "       [15.432086 ],\n",
       "       [25.19731  ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.predict(X_test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
